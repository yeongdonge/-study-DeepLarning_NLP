{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers','footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "news_df = pd.DataFrame({'document':documents})\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\",\" \")\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x : ' '.join([w for w in x.split() if len(w) > 3]))\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda  x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [well, sure, story, seem, biased, disagree, st...\n",
      "1    [yeah, expect, people, read, actually, accept,...\n",
      "2    [although, realize, principle, strongest, poin...\n",
      "3    [notwithstanding, legitimate, fuss, proposal, ...\n",
      "4    [well, change, scoring, playoff, pool, unfortu...\n",
      "Name: clean_doc, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_doc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(52, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(tokenized_doc)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
    "print(corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faith\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64281"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.018*\"government\" + 0.013*\"president\" + 0.010*\"encryption\" + 0.010*\"public\"')\n",
      "(1, '0.011*\"power\" + 0.008*\"ground\" + 0.008*\"cars\" + 0.008*\"engine\"')\n",
      "(2, '0.005*\"mark\" + 0.005*\"mike\" + 0.005*\"smith\" + 0.004*\"year\"')\n",
      "(3, '0.037*\"jesus\" + 0.021*\"christian\" + 0.021*\"bible\" + 0.018*\"church\"')\n",
      "(4, '0.013*\"windows\" + 0.012*\"thanks\" + 0.012*\"would\" + 0.011*\"know\"')\n",
      "(5, '0.026*\"scsi\" + 0.019*\"data\" + 0.010*\"tobacco\" + 0.009*\"chip\"')\n",
      "(6, '0.010*\"available\" + 0.010*\"information\" + 0.009*\"mail\" + 0.008*\"list\"')\n",
      "(7, '0.017*\"would\" + 0.014*\"people\" + 0.011*\"think\" + 0.011*\"know\"')\n",
      "(8, '0.023*\"window\" + 0.018*\"server\" + 0.014*\"motif\" + 0.012*\"widget\"')\n",
      "(9, '0.016*\"health\" + 0.014*\"medical\" + 0.010*\"entries\" + 0.009*\"disease\"')\n",
      "(10, '0.011*\"people\" + 0.007*\"jews\" + 0.006*\"world\" + 0.005*\"jewish\"')\n",
      "(11, '0.061*\"space\" + 0.021*\"nasa\" + 0.013*\"launch\" + 0.012*\"earth\"')\n",
      "(12, '0.041*\"armenian\" + 0.036*\"armenians\" + 0.015*\"said\" + 0.014*\"armenia\"')\n",
      "(13, '0.010*\"would\" + 0.006*\"system\" + 0.006*\"used\" + 0.005*\"could\"')\n",
      "(14, '0.086*\"drive\" + 0.047*\"disk\" + 0.031*\"hard\" + 0.027*\"drives\"')\n",
      "(15, '0.022*\"period\" + 0.018*\"play\" + 0.012*\"power\" + 0.012*\"detroit\"')\n",
      "(16, '0.059*\"file\" + 0.033*\"output\" + 0.030*\"entry\" + 0.023*\"program\"')\n",
      "(17, '0.051*\"israel\" + 0.032*\"israeli\" + 0.021*\"arab\" + 0.014*\"water\"')\n",
      "(18, '0.018*\"price\" + 0.014*\"good\" + 0.008*\"bike\" + 0.008*\"simms\"')\n",
      "(19, '0.026*\"game\" + 0.025*\"team\" + 0.022*\"year\" + 0.020*\"games\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 20\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "topics = ldamodel.print_topics(num_words = 4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.018*\"government\" + 0.013*\"president\" + 0.010*\"encryption\" + 0.010*\"public\" + 0.008*\"security\" + 0.008*\"clipper\" + 0.007*\"chip\" + 0.007*\"states\" + 0.007*\"state\" + 0.007*\"privacy\"'), (1, '0.011*\"power\" + 0.008*\"ground\" + 0.008*\"cars\" + 0.008*\"engine\" + 0.007*\"speed\" + 0.006*\"wire\" + 0.006*\"high\" + 0.006*\"bike\" + 0.006*\"used\" + 0.005*\"front\"'), (2, '0.005*\"mark\" + 0.005*\"mike\" + 0.005*\"smith\" + 0.004*\"year\" + 0.004*\"defense\" + 0.004*\"dave\" + 0.004*\"great\" + 0.003*\"steve\" + 0.003*\"stats\" + 0.003*\"draft\"'), (3, '0.037*\"jesus\" + 0.021*\"christian\" + 0.021*\"bible\" + 0.018*\"church\" + 0.016*\"christians\" + 0.015*\"faith\" + 0.015*\"christ\" + 0.012*\"believe\" + 0.011*\"truth\" + 0.010*\"christianity\"'), (4, '0.013*\"windows\" + 0.012*\"thanks\" + 0.012*\"would\" + 0.011*\"know\" + 0.011*\"like\" + 0.010*\"anyone\" + 0.009*\"please\" + 0.009*\"problem\" + 0.008*\"need\" + 0.008*\"card\"'), (5, '0.026*\"scsi\" + 0.019*\"data\" + 0.010*\"tobacco\" + 0.009*\"chip\" + 0.008*\"byte\" + 0.008*\"bits\" + 0.008*\"input\" + 0.008*\"channel\" + 0.007*\"voltage\" + 0.006*\"mode\"'), (6, '0.010*\"available\" + 0.010*\"information\" + 0.009*\"mail\" + 0.008*\"list\" + 0.007*\"also\" + 0.007*\"send\" + 0.007*\"image\" + 0.006*\"software\" + 0.006*\"data\" + 0.005*\"university\"'), (7, '0.017*\"would\" + 0.014*\"people\" + 0.011*\"think\" + 0.011*\"know\" + 0.010*\"like\" + 0.008*\"time\" + 0.007*\"said\" + 0.007*\"well\" + 0.007*\"even\" + 0.006*\"could\"'), (8, '0.023*\"window\" + 0.018*\"server\" + 0.014*\"motif\" + 0.012*\"widget\" + 0.011*\"application\" + 0.011*\"display\" + 0.010*\"version\" + 0.010*\"available\" + 0.010*\"code\" + 0.009*\"export\"'), (9, '0.016*\"health\" + 0.014*\"medical\" + 0.010*\"entries\" + 0.009*\"disease\" + 0.008*\"pain\" + 0.007*\"among\" + 0.007*\"patients\" + 0.007*\"study\" + 0.006*\"doctor\" + 0.005*\"research\"'), (10, '0.011*\"people\" + 0.007*\"jews\" + 0.006*\"world\" + 0.005*\"jewish\" + 0.005*\"history\" + 0.005*\"many\" + 0.004*\"also\" + 0.004*\"turkish\" + 0.004*\"greek\" + 0.004*\"human\"'), (11, '0.061*\"space\" + 0.021*\"nasa\" + 0.013*\"launch\" + 0.012*\"earth\" + 0.011*\"satellite\" + 0.010*\"shuttle\" + 0.009*\"orbit\" + 0.008*\"lunar\" + 0.008*\"mission\" + 0.008*\"moon\"'), (12, '0.041*\"armenian\" + 0.036*\"armenians\" + 0.015*\"said\" + 0.014*\"armenia\" + 0.011*\"azerbaijan\" + 0.009*\"turkey\" + 0.009*\"genocide\" + 0.008*\"soviet\" + 0.008*\"turkish\" + 0.008*\"soldiers\"'), (13, '0.010*\"would\" + 0.006*\"system\" + 0.006*\"used\" + 0.005*\"could\" + 0.005*\"many\" + 0.005*\"even\" + 0.005*\"example\" + 0.005*\"much\" + 0.004*\"like\" + 0.004*\"must\"'), (14, '0.086*\"drive\" + 0.047*\"disk\" + 0.031*\"hard\" + 0.027*\"drives\" + 0.022*\"controller\" + 0.020*\"floppy\" + 0.018*\"scsi\" + 0.017*\"tape\" + 0.010*\"disks\" + 0.009*\"bios\"'), (15, '0.022*\"period\" + 0.018*\"play\" + 0.012*\"power\" + 0.012*\"detroit\" + 0.011*\"goal\" + 0.011*\"pittsburgh\" + 0.010*\"kings\" + 0.009*\"puck\" + 0.009*\"flames\" + 0.008*\"calgary\"'), (16, '0.059*\"file\" + 0.033*\"output\" + 0.030*\"entry\" + 0.023*\"program\" + 0.014*\"files\" + 0.014*\"line\" + 0.013*\"section\" + 0.013*\"build\" + 0.011*\"check\" + 0.011*\"rules\"'), (17, '0.051*\"israel\" + 0.032*\"israeli\" + 0.021*\"arab\" + 0.014*\"water\" + 0.011*\"palestinian\" + 0.010*\"arabs\" + 0.007*\"lebanon\" + 0.007*\"palestinians\" + 0.007*\"israelis\" + 0.006*\"peace\"'), (18, '0.018*\"price\" + 0.014*\"good\" + 0.008*\"bike\" + 0.008*\"simms\" + 0.007*\"excellent\" + 0.007*\"condition\" + 0.006*\"sell\" + 0.006*\"cost\" + 0.005*\"sold\" + 0.005*\"selling\"'), (19, '0.026*\"game\" + 0.025*\"team\" + 0.022*\"year\" + 0.020*\"games\" + 0.014*\"season\" + 0.013*\"players\" + 0.013*\"hockey\" + 0.012*\"last\" + 0.012*\"league\" + 0.010*\"play\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_NUMEXPR_INSTALLED' from 'pandas.core.computation.check' (C:\\Users\\User\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\check.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-311e2a435b6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim_models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\gensim_models.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \"\"\"\n\u001b[0;32m    122\u001b[0m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[0mterm_frequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm_topic_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m     topic_info = _topic_info(topic_term_dists, topic_proportion,\n\u001b[0m\u001b[0;32m    440\u001b[0m                              \u001b[0mterm_frequency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                              n_jobs, start_index)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py\u001b[0m in \u001b[0;36m_topic_info\u001b[1;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs, start_index)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;31m# this determines the R terms that are displayed when no topic is selected.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mtt_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopic_term_dists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[0mtopic_given_term\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"topic_term_dists / tt_sum\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m     \u001b[0mlog_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"topic_given_term.T / topic_proportion\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"topic_given_term * log_1.T\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\eval.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;34m\"multi-line expressions are only valid in the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;34m\"context of data, use DataFrame.eval\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m         )\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[0m_check_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\eval.py\u001b[0m in \u001b[0;36m_check_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mEngine\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \"\"\"\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNUMEXPR_INSTALLED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_NUMEXPR_INSTALLED' from 'pandas.core.computation.check' (C:\\Users\\User\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\check.py)"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
