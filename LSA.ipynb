{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A=np.array([[0,0,0,1,0,1,1,0,0],[0,0,0,1,1,0,1,0,0],[0,1,1,0,2,0,0,0,0],[1,0,0,0,0,0,0,1,1]])\n",
    "np.shape(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24  0.75  0.    0.62]\n",
      " [ 0.51  0.44 -0.   -0.74]\n",
      " [ 0.83 -0.49 -0.    0.27]\n",
      " [ 0.   -0.    1.   -0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, s, VT = np.linalg.svd(A, full_matrices=True)\n",
    "print(U.round(2))\n",
    "np.shape(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.69 2.05 1.73 0.77]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(s.round(2))\n",
    "np.shape(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.69 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   2.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.73 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.77 0.   0.   0.   0.   0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.zeros((4,9))\n",
    "S[:4, :4] = np.diag(s)\n",
    "print(S.round(2))\n",
    "np.shape(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.31  0.31  0.28  0.8   0.09  0.28  0.    0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
      " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
      " [-0.    0.35  0.35 -0.16 -0.25  0.8  -0.16  0.    0.  ]\n",
      " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
      " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
      " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(VT.round(2))\n",
    "np.shape(VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A, np.dot(np.dot(U,S), VT).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.69 0.  ]\n",
      " [0.   2.05]]\n"
     ]
    }
   ],
   "source": [
    "S=S[:2,:2]\n",
    "print(S.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24  0.75]\n",
      " [ 0.51  0.44]\n",
      " [ 0.83 -0.49]\n",
      " [ 0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "U=U[:,:2]\n",
    "print(U.round(2))\n",
    "# 문서의 개수 x 토픽의 수 t의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.31  0.31  0.28  0.8   0.09  0.28  0.    0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "VT=VT[:2,:]\n",
    "print(VT.round(2))\n",
    "# 토픽의 수 x 단어의 개수의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1]]\n",
      "[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]\n",
      " [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]\n",
      " [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "A_prime = np.dot(np.dot(U,S), VT)\n",
    "print(A)\n",
    "print(A_prime.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리\n",
    "news_df = pd.DataFrame({'document':documents})\n",
    "#특수 문자 제거\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-z,A-Z]\",\" \")\n",
    "# 길이가 3이하인 단어 제거\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x : ' '.join([w for w in x.split() if len(w) > 3]))\n",
    "# 전체 단어에 대한 소문자 변환\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah, expect people read faq, actually accept hard atheism need little leap faith, jimmy your logic runs steam jim, sorry pity you, sorry that have these feelings denial about faith need well, just pretend that will happily ever after anyway maybe start newsgroup, atheist hard, bummin much bye, forget your flintstone chewables bake timmons,'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) #토큰화\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "# 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yeah,', 'expect', 'people', 'read', 'faq,', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith,', 'jimmy', 'logic', 'runs', 'steam', 'jim,', 'sorry', 'pity', 'you,', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well,', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup,', 'atheist', 'hard,', 'bummin', 'much', 'bye,', 'forget', 'flintstone', 'chewables', 'bake', 'timmons,']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 행렬 만들기\n",
    "# 역토큰화\n",
    "detokenized_doc = []\n",
    "for i in range(len(news_df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "    \n",
    "news_df['clean_doc'] = detokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah, expect people read faq, actually accept hard atheism need little leap faith, jimmy logic runs steam jim, sorry pity you, sorry feelings denial faith need well, pretend happily ever anyway maybe start newsgroup, atheist hard, bummin much bye, forget flintstone chewables bake timmons,'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 1000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000, max_df=0.5, smooth_idf=-True)\n",
    "\n",
    "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n",
    "svd_model.fit(X)\n",
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('like', 0.21349), ('know', 0.20003), ('people', 0.19229), ('think', 0.17717), ('good', 0.15105), ('time', 0.1442), ('thanks', 0.11571), ('make', 0.10872), ('right', 0.10705)]\n",
      "Topic 2: [('thanks', 0.32447), ('windows', 0.29158), ('card', 0.18155), ('drive', 0.17559), ('mail', 0.15051), ('file', 0.14701), ('advance', 0.12446), ('files', 0.11542), ('software', 0.11396)]\n",
      "Topic 3: [('game', 0.37087), ('team', 0.32504), ('year', 0.27875), ('games', 0.25403), ('season', 0.18456), ('players', 0.1612), ('good', 0.15675), ('play', 0.15052), ('hockey', 0.13889)]\n",
      "Topic 4: [('drive', 0.54434), ('scsi', 0.20589), ('hard', 0.15932), ('disk', 0.15681), ('drives', 0.14049), ('card', 0.13883), ('problem', 0.10705), ('controller', 0.10447), ('floppy', 0.09785)]\n",
      "Topic 5: [('windows', 0.40336), ('file', 0.25349), ('window', 0.18013), ('files', 0.15978), ('program', 0.13701), ('using', 0.12711), ('problem', 0.10428), ('running', 0.09066), ('version', 0.08801)]\n",
      "Topic 6: [('government', 0.16049), ('chip', 0.16039), ('mail', 0.15663), ('space', 0.15167), ('information', 0.13543), ('encryption', 0.12863), ('data', 0.12787), ('sale', 0.12073), ('email', 0.11867)]\n",
      "Topic 7: [('like', 0.66945), ('bike', 0.1428), ('chip', 0.11358), ('know', 0.10585), ('sounds', 0.10368), ('looks', 0.07978), ('look', 0.072), ('sure', 0.06502), ('clipper', 0.06468)]\n",
      "Topic 8: [('card', 0.4722), ('video', 0.22392), ('sale', 0.21109), ('monitor', 0.1566), ('offer', 0.14566), ('price', 0.14196), ('jesus', 0.13264), ('condition', 0.11693), ('drivers', 0.11492)]\n",
      "Topic 9: [('know', 0.46015), ('card', 0.32945), ('chip', 0.17752), ('government', 0.1553), ('video', 0.14045), ('people', 0.13301), ('clipper', 0.10891), ('encryption', 0.1034), ('drivers', 0.0922)]\n",
      "Topic 10: [('good', 0.43443), ('know', 0.21663), ('time', 0.18047), ('bike', 0.11878), ('problem', 0.08485), ('jesus', 0.07263), ('work', 0.07024), ('want', 0.06705), ('long', 0.06364)]\n",
      "Topic 11: [('think', 0.78915), ('chip', 0.11442), ('thanks', 0.09437), ('clipper', 0.08349), ('encryption', 0.08239), ('people', 0.08122), ('need', 0.07341), ('mail', 0.07296), ('good', 0.06032)]\n",
      "Topic 12: [('thanks', 0.35712), ('good', 0.24675), ('bike', 0.214), ('right', 0.20088), ('problem', 0.19454), ('people', 0.158), ('window', 0.10871), ('advance', 0.10503), ('time', 0.10413)]\n",
      "Topic 13: [('good', 0.34863), ('people', 0.32618), ('know', 0.28514), ('windows', 0.28167), ('file', 0.19055), ('sale', 0.17305), ('files', 0.15242), ('price', 0.12218), ('condition', 0.10782)]\n",
      "Topic 14: [('space', 0.40642), ('think', 0.24491), ('know', 0.18198), ('nasa', 0.1546), ('problem', 0.1237), ('year', 0.12319), ('israel', 0.0988), ('time', 0.08735), ('years', 0.08556)]\n",
      "Topic 15: [('good', 0.32193), ('space', 0.31631), ('card', 0.23505), ('people', 0.1564), ('time', 0.13682), ('nasa', 0.11785), ('thanks', 0.11523), ('like', 0.10497), ('year', 0.10322)]\n",
      "Topic 16: [('people', 0.49253), ('problem', 0.19184), ('window', 0.14419), ('time', 0.13487), ('game', 0.12181), ('want', 0.0773), ('work', 0.07471), ('using', 0.07159), ('bike', 0.06217)]\n",
      "Topic 17: [('time', 0.36651), ('bike', 0.28149), ('right', 0.22489), ('windows', 0.20322), ('file', 0.19676), ('need', 0.11662), ('really', 0.10766), ('files', 0.10467), ('going', 0.0954)]\n",
      "Topic 18: [('time', 0.57104), ('file', 0.18348), ('problem', 0.17898), ('think', 0.13142), ('mail', 0.10078), ('israel', 0.0987), ('good', 0.08529), ('long', 0.08457), ('address', 0.0755)]\n",
      "Topic 19: [('file', 0.44676), ('need', 0.26052), ('files', 0.17858), ('card', 0.17535), ('right', 0.16221), ('problem', 0.14692), ('game', 0.11408), ('good', 0.10329), ('help', 0.10311)]\n",
      "Topic 20: [('problem', 0.33771), ('file', 0.25135), ('thanks', 0.24134), ('used', 0.19453), ('chip', 0.1351), ('space', 0.12133), ('sale', 0.11665), ('jesus', 0.0872), ('offer', 0.08511)]\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "def get_tophics(components, feature_names, n = 5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n-n:-1]])\n",
    "get_tophics(svd_model.components_, terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function get_tophics at 0x00000281AA53C8B0>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
